Athena Tables Creation DDL:
---------------------------->

create external table grab_test.supply_demand_ratio_streaming(
  geo_hash string,
  supply_demand_ratio double)
stored as parquet
location 's3://grab-test-data/supply_demand_ratio';


CREATE EXTERNAL TABLE `users_data_batch`(
  `geo_hash` string,
  `count` int,
  `time_stamp` int)
stored as parquet
LOCATION
  's3://grab-test-data/user_data';


  CREATE EXTERNAL TABLE `driver_data_batch`(
    `geo_hash` string,
    `count` int,
    `time_stamp` int)
  stored as parquet
  LOCATION
    's3://grab-test-data/driver_data'


    CREATE EXTERNAL TABLE `weather_data_streaming`(
      `geo_hash` string,
      `temparature` double,
      `precipitation` double)
stored as parquet
LOCATION
  's3://grab-test-data/weather_data_streaming'


CREATE EXTERNAL TABLE `weather_data_batch`(
  `geo_hash` string,
  `temparature` double,
  `precipitation` double,
  `time_stamp` int)
  stored as parquet
  LOCATION
  's3://grab-test-data/weather_data_batch'



  CREATE EXTERNAL TABLE `traffic_congestion_rating_streaming`(
    `geohash` string,
    `congest` int)
   stored as parquet
   location 's3://grab-test-data/congestion_data_streaming/'


CREATE EXTERNAL TABLE `traffic_congestion_rating_batch`(
  `geohash` string,
  `congest` int,
  `time_stamp` int)
  stored as parquet
  LOCATION
  's3://grab-test-data/congestion_data_batch'


  create external table hourly_data_aggregation(
  geo_hash string, time_stamp string, congest int, temparature double, precipitation double, demandCount int, supplyCount int)
  stored as parquet
  location 's3://grab-test-data/hourly_data_aggregation'


Tableau Queries to Athena:
---------------------------->
1) For streaming query the grab_test.supply_demand_ratio_streaming directly and display it on tableau dashboard.

select congestion.geohash, case when sd.supply_demand_ratio is not null then sd.supply_demand_ratio else 0.0 END as supply_demand_ratio,
congestion.congest
from  grab_test.traffic_congestion_rating_streaming congestion
left outer join grab_test.supply_demand_ratio_streaming sd
on congestion.geohash = sd.geo_hash;

#yet to see whether to join the weather streaming dataset

Available geo hashes:
----------------------
dr5r81
dr5r8q
dr5r82
dr5r8r
dr5r83
dr5r84
dr5r8m
dr5r8n
dr5r80
dr5r8p
dr5r85
dr5r2p
dr5r86
dr5r87
dr5r2r
dr5r8j
dr5r8k
dr5rb0
dr5r8h
dr5rb2

2) For showing the data for batch processing take the input parameters of starting time in yyyy-MM-dd and ending time in yyyy-MM-dd and the geohash from user



select driver_data.geo_hash, driver_data.count as supply, user_data.count as demand, weather_data.temparature, weather_data.precipitation, congestion.traffic_congestion
from grab_test.driver_data_batch driver_data
join grab_test.users_data_batch user_data
on driver_data.geo_hash = user_data.geo_hash
and date_format(from_unixtime(driver_data.time_stamp),'%Y-%m-%d') = date_format(from_unixtime(user_data.time_stamp),'%Y-%m-%d')
join grab_test.weather_data_batch weather_data
on driver_data.geo_hash = weather_data.geo_hash
and date_format(from_unixtime(driver_data.time_stamp),'%Y-%m-%d') = date_format(from_unixtime(weather_data.time_stamp),'%Y-%m-%d')
join grab_test.traffic_congestion_rating_batch congestion
on driver_data.geo_hash = congestion.geo_hash
and date_format(from_unixtime(driver_data.time_stamp),'%Y-%m-%d') = date_format(from_unixtime(congestion.time_stamp),'%Y-%m-%d')
where driver_data.geo_hash='geo_hash'
and date_format(from_unixtime(driver_data.time_stamp),'%Y-%m-%d') <= format_datetime(date_parse(starting_time_from_user_param, '%Y-%m-%d'), 'Y-m-d')
and date_format(from_unixtime(driver_data.time_stamp),'%Y-%m-%d') >= format_datetime(date_parse(ending_time_from_user_param, '%Y-%m-%d'), 'Y-m-d');

#having doubt whether to filter based on time from grab_test.users_data_batch table and grab_test.weather_data_batch




#from grab_test.driver_data_batch driver_data
#join grab_test.users_data_batch user_data
#and date_format(from_unixtime(driver_data.time_stamp),'%Y-%m-%d') = date_format(from_unixtime(user_data.time_stamp),'%Y-%m-%d')
#join grab_test.weather_data_batch weather_data
#on driver_data.geo_hash = weather_data.geo_hash
#and date_format(from_unixtime(driver_data.time_stamp),'%Y-%m-%d') = date_format(from_unixtime(weather_data.time_stamp),'%Y-%m-%d')
#join grab_test.traffic_congestion_rating_batch congestion
#on driver_data.geo_hash = congestion.geo_hash
#and date_format(from_unixtime(driver_data.time_stamp),'%Y-%m-%d') = date_format(from_unixtime(congestion.time_stamp),'%Y-%m-%d')
#where driver_data.geo_hash='geo_hash'
#and date_format(from_unixtime(driver_data.time_stamp),'%Y-%m-%d') <= format_datetime(date_parse('2018-09-08', '%Y-%m-%d'), 'Y-m-d')
#and date_format(from_unixtime(driver_data.time_stamp),'%Y-%m-%d') >= format_datetime(date_parse('2018-09-01', '%Y-%m-%d'), 'Y-m-d');

#SELECT date_parse(ts,'%Y%m%dT%h%i%s') FROM timestamptestcsv3
#select driver_data.geo_hash, driver_data.count as supply, user_data.count as demand, weather_data.temparature, weather_data.precipitation
#from grab_test.driver_data_batch driver_data
#join grab_test.users_data_batch user_data
#on driver_data.geo_hash = user_data.geo_hash
#join grab_test.weather_data_batch weather_data
#on driver_data.geo_hash = weather_data.geo_hash
#where ;
